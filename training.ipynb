{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stop words\n",
    "stop_words = set([\n",
    "    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\",\n",
    "    \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\",\n",
    "    \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\n",
    "    \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n",
    "    \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\",\n",
    "    \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\",\n",
    "    \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\",\n",
    "    \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\",\n",
    "    \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\",\n",
    "    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\",\n",
    "    \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n",
    "    \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"nor\", \"only\",\n",
    "    \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\",\n",
    "    \"don\", \"should\", \"now\", \"RT\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing Steps:\n",
    "\n",
    "1. Convert to lower case\n",
    "2. Tokenization\n",
    "3. Remove stop words\n",
    "4. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"ucberkeley-dlab/measuring-hate-speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the text of the first 5 examples before removing stop words\n",
    "for i in range(5):\n",
    "    print(df['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "\n",
    "#make a copy of df for preprocessing\n",
    "data = df.copy()\n",
    "# convert to lowercase\n",
    "data['text'] = data['text'].str.lower()\n",
    "\n",
    "# convert to list\n",
    "data['text'] = data['text'].str.split()\n",
    "\n",
    "# remove stopwords\n",
    "data['text'] = data['text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "# lemmatize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['text'] = data['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the text of the first 5 examples after preprocessing\n",
    "for i in range(5):\n",
    "    print(data['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the text of the first 5 examples an their classes\n",
    "for i in range(5):\n",
    "    print(\"Example \", i)\n",
    "    print(\"Racism:\", data['target_race'][i])\n",
    "    print(\"Sexism:\", data['target_gender'][i])\n",
    "    print(\"Xenophobia:\", data['target_origin'][i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of rows targeting race, gender, and origin\n",
    "num_race = 0\n",
    "num_gender = 0\n",
    "num_origin = 0\n",
    "for i, row in data.iterrows():\n",
    "    if row['target_race'] == 1:\n",
    "        num_race += 1\n",
    "    if row['target_gender'] == 1:\n",
    "        num_gender += 1\n",
    "    if row['target_origin'] == 1:\n",
    "        num_origin += 1\n",
    "\n",
    "print(\"Num_race:\", num_race)\n",
    "print(\"Num_gender:\", num_gender)\n",
    "print(\"Num_origin:\", num_origin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through the data and create 3 lists representing whether each example is racist, sexist, or xenophobic\n",
    "racism = []\n",
    "sexism = []\n",
    "xenophobia = []\n",
    "for i, row in data.iterrows():\n",
    "    racism.append(1 if row['target_race'] == 1 else 0)\n",
    "    sexism.append(1 if row['target_gender'] == 1 else 0)\n",
    "    xenophobia.append(1 if row['target_origin'] == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 1: random assignment\n",
    "# Randomly choose a class and keep track of how accurate the model is\n",
    "import random\n",
    "correct_racism = 0\n",
    "correct_sexism = 0\n",
    "correct_xenophobia = 0\n",
    "for i in range(len(racism)):\n",
    "    if racism[i] == random.randint(0, 1):\n",
    "        correct_racism += 1\n",
    "    if sexism[i] == random.randint(0, 1):\n",
    "        correct_sexism += 1\n",
    "    if xenophobia[i] == random.randint(0, 1):\n",
    "        correct_xenophobia += 1\n",
    "\n",
    "print(\"Random assignment accuracy for racism:\", correct_racism / len(racism))\n",
    "print(\"Random assignment accuracy for sexism:\", correct_sexism / len(sexism))\n",
    "print(\"Random assignment accuracy for xenophobia:\", correct_xenophobia / len(xenophobia))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 2: majority class\n",
    "# Choose the majority class and keep track of how accurate the model is\n",
    "majority_racism = 1 if num_race > len(racism) / 2 else 0\n",
    "majority_sexism = 1 if num_gender > len(sexism) / 2 else 0\n",
    "majority_xenophobia = 1 if num_origin > len(xenophobia) / 2 else 0\n",
    "\n",
    "correct_racism = 0\n",
    "correct_sexism = 0\n",
    "correct_xenophobia = 0\n",
    "for i in range(len(racism)):\n",
    "    if racism[i] == majority_racism:\n",
    "        correct_racism += 1\n",
    "    if sexism[i] == majority_sexism:\n",
    "        correct_sexism += 1\n",
    "    if xenophobia[i] == majority_xenophobia:\n",
    "        correct_xenophobia += 1\n",
    "\n",
    "print(\"Majority class accuracy for racism:\", correct_racism / len(racism)) \n",
    "print(\"Majority class accuracy for sexism:\", correct_sexism / len(sexism))\n",
    "print(\"Majority class accuracy for xenophobia:\", correct_xenophobia / len(xenophobia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier object which consists of three MLP classifiers, one for each class (racism, sexism, xenophobia)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self, hidden_layer_sizes=(50,), alpha=0.0005):\n",
    "        self.racism_classifier = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, alpha=alpha)\n",
    "        self.sexism_classifier = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, alpha=alpha)\n",
    "        self.xenophobia_classifier = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, alpha=alpha)\n",
    "\n",
    "    def fit(self, train_data, train_racism, train_sexism, train_xenophobia):\n",
    "        self.racism_classifier.fit(train_data, train_racism)\n",
    "        self.sexism_classifier.fit(train_data, train_sexism)\n",
    "        self.xenophobia_classifier.fit(train_data, train_xenophobia)\n",
    "\n",
    "    def predict(self, racism, sexism, xenophobia):\n",
    "        racism_predictions = self.racism_classifier.predict(racism)\n",
    "        sexism_predictions = self.sexism_classifier.predict(sexism)\n",
    "        xenophobia_predictions = self.xenophobia_classifier.predict(xenophobia)\n",
    "\n",
    "        return racism_predictions, sexism_predictions, xenophobia_predictions\n",
    "    \n",
    "    def score(self, racism_pred, racism_true, sexism_pred, sexism_true, xenophobia_pred, xenophobia_true):\n",
    "        racism_accuracy = f1_score(racism_true, racism_pred)\n",
    "        sexism_accuracy = f1_score(sexism_true, sexism_pred)\n",
    "        xenophobia_accuracy = f1_score(xenophobia_true, xenophobia_pred)\n",
    "\n",
    "        return racism_accuracy, sexism_accuracy, xenophobia_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep Training Data\n",
    "\n",
    "# convert the list of words to strings\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# split the data into training and testing sets\n",
    "train_data = data['text'][0:len(data) // 10 * 7]\n",
    "dev_data = data['text'][len(data) // 10 * 7:len(data) // 10 * 8]\n",
    "test_data = data['text'][len(data) // 10 * 8:]\n",
    "\n",
    "train_racism = racism[0:len(data) // 10 * 7]\n",
    "dev_racism = racism[len(data) // 10 * 7:len(data) // 10 * 8]\n",
    "test_racism = racism[len(data) // 10 * 8:]\n",
    "\n",
    "train_sexism = sexism[0:len(data) // 10 * 7]\n",
    "dev_sexism = sexism[len(data) // 10 * 7:len(data) // 10 * 8]\n",
    "test_sexism = sexism[len(data) // 10 * 8:]\n",
    "\n",
    "train_xenophobia = xenophobia[0:len(data) // 10 * 7]\n",
    "dev_xenophobia = xenophobia[len(data) // 10 * 7:len(data) // 10 * 8]\n",
    "test_xenophobia = xenophobia[len(data) // 10 * 8:]\n",
    "\n",
    "# create a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit the vectorizer on the training data\n",
    "vectorizer.fit(train_data)\n",
    "\n",
    "# transform the training and testing data\n",
    "train_data = vectorizer.transform(train_data)\n",
    "dev_data = vectorizer.transform(dev_data)\n",
    "test_data = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best hidden layer node size\n",
    "classifier = Classifier()\n",
    "best_accuracy = 0\n",
    "best_i = 0\n",
    "\n",
    "for i in range(0, train_data.shape[0] - 1000, 1000):\n",
    "    classifier.fit(train_data[i:i + 1000], train_racism[i:i + 1000], train_sexism[i:i + 1000], train_xenophobia[i:i + 1000])\n",
    "    racism_pred, sexism_pred, xenophobia_pred = classifier.predict(dev_data, dev_data, dev_data)\n",
    "    racism_accuracy, sexism_accuracy, xenophobia_accuracy = classifier.score(racism_pred, dev_racism, sexism_pred, dev_sexism, xenophobia_pred, dev_xenophobia)\n",
    "    print(\"Racism accuracy after training on\", i + 1000, \"examples:\", racism_accuracy)\n",
    "    print(\"Sexism accuracy after training on\", i + 1000, \"examples:\", sexism_accuracy)\n",
    "    print(\"Xenophobia accuracy after training on\", i + 1000, \"examples:\", xenophobia_accuracy)\n",
    "    print()\n",
    "    if racism_accuracy + sexism_accuracy + xenophobia_accuracy > best_accuracy:\n",
    "        best_accuracy = racism_accuracy + sexism_accuracy + xenophobia_accuracy\n",
    "        best_i = i\n",
    "        joblib.dump(classifier, \"best_classifier.pt\")\n",
    "\n",
    "print(\"Best average accuracy:\", best_accuracy / 3)\n",
    "print(\"Found after training on\", best_i + 1000, \"examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "racism_pred, sexism_pred, xenophobia_pred = classifier.predict(test_data, test_data, test_data)\n",
    "racism_accuracy, sexism_accuracy, xenophobia_accuracy = classifier.score(racism_pred, test_racism, sexism_pred, test_sexism, xenophobia_pred, test_xenophobia)\n",
    "print(\"Racism accuracy on test set:\", racism_accuracy)\n",
    "print(\"Sexism accuracy on test set:\", sexism_accuracy)\n",
    "print(\"Xenophobia accuracy on test set:\", xenophobia_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
